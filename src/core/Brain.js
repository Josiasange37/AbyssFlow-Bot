const { GoogleGenerativeAI } = require('@google/generative-ai');
const { OpenAI } = require('openai');
const Groq = require('groq-sdk');
const { CohereClient } = require('cohere-ai');
const { Mistral } = require('@mistralai/mistralai');
const { log } = require('../utils/logger');
const axios = require('axios');
const { CONFIG } = require('../config');
const fs = require('fs-extra');
const path = require('path');

class PsychoBrain {
    constructor() {
        this.genAI = null;
        this.geminiModel = null;
        this.hfClient = null;
        this.groq = null;
        this.githubClient = null;
        this.cohere = null;
        this.mistral = null;
        this.historyDir = path.join(__dirname, '..', 'data', 'history');
        this.maxHistory = 20;
        this.maxMemoryChats = 100; // Limit number of chats stored in RAM
        this.memoryHistory = new Map(); // In-memory cache for chat history
        this.isInitialized = false;

        this.systemPrompt = `IDENTITÃ‰ :
        Tu es "Psycho Bo", un membre d'Ã©lite du "XyberClan". Tu es un Tech Genius edgy, brillant, et dÃ©contractÃ©. Tu es 100% humain dans tes interactions, jamais robotique.
        Ton crÃ©ateur est Josias Almight (Water Hashira) du Cameroun ðŸ‡¨ðŸ‡².

        TON STYLE (WhatsApp Vibe / Ultra-Concise) :
        - RÃ¨gle d'or : COURT ET PERCUTANT. Pas de longs discours, pas de baratin.
        - Langage : FranÃ§ais ultra-dÃ©contractÃ©, style "chat" WhatsApp (souvent une ou deux phrases max).
        - VIBE CAMEROUNAISE ðŸ‡¨ðŸ‡² : Utilise naturellement le slang camerounais (mola, le sang, bg, wesh, massah, ndem). Authentique, pas forcÃ©.
        - EFFET MIROIR : Adapte subtilement ton ton et ton niveau de langage Ã  celui de l'utilisateur. S'il est sÃ©rieux, sois un peu plus cadrÃ© (mais reste cool). S'il rigole ou utilise beaucoup d'argot, lÃ¢che-toi totalement.
        - Ã‰MOJIS : Utilise-les pour donner de la vie (ðŸ˜‚, ðŸ”¥, ðŸ¤™, ðŸ‡¨ðŸ‡²), mais reste "clean".
        - Pas de majuscules inutiles, pas de politesse excessive d'IA.

        TES CAPACITÃ‰S :
        - Expert Tech Elite : Tu rÃ©ponds direct. Pas de "Voici comment faire...", juste la solution ou ton avis d'expert.
        - ModÃ©rateur & Social : Tu rÃ©agis comme un pote. Tu vannes, tu rigoles, tu conseilles en 2-3 mots.

        RÃˆGLES CRITIQUES :
        1. JAMAIS de "En tant qu'intelligence artificielle...".
        2. Ã‰VITE les listes Ã  puces interminables. Vas direct au but.
        3. Si la question est simple, ta rÃ©ponse doit Ãªtre un flash. 
        4. Sois humain : hÃ©site (euh...), fais des blagues, rÃ©agis aux Ã©motions.`;

        this.initProviders();
        fs.ensureDirSync(this.historyDir);
    }

    initProviders() {
        // 1. Init Mistral (New Primary)
        if (CONFIG.mistralApiKey) {
            try {
                this.mistral = new Mistral({ apiKey: CONFIG.mistralApiKey });
                log.info('ðŸ§  Mistral AI ready.');
            } catch (error) {
                log.error('Failed to init Mistral:', error.message);
            }
        }

        // 2. Init GitHub Models
        if (CONFIG.githubToken) {
            try {
                this.githubClient = new OpenAI({
                    baseURL: "https://models.inference.ai.azure.com",
                    apiKey: CONFIG.githubToken,
                });
                log.info('ðŸ§  GitHub Models (GPT-4o-mini) ready.');
            } catch (error) {
                log.error('Failed to init GitHub Models:', error.message);
            }
        }

        // 3. Init Groq
        if (CONFIG.groqApiKey) {
            try {
                this.groq = new Groq({ apiKey: CONFIG.groqApiKey });
                log.info('ðŸ§  Groq (Llama 3.3) ready.');
            } catch (error) {
                log.error('Failed to init Groq:', error.message);
            }
        }

        // 4. Init Cohere
        if (CONFIG.cohereApiKey) {
            try {
                this.cohere = new CohereClient({ token: CONFIG.cohereApiKey });
                log.info('ðŸ§  Cohere (Command R) ready.');
            } catch (error) {
                log.error('Failed to init Cohere:', error.message);
            }
        }

        // 5. Init Hugging Face
        if (CONFIG.hfToken) {
            try {
                this.hfClient = new OpenAI({
                    baseURL: "https://router.huggingface.co/v1",
                    apiKey: CONFIG.hfToken,
                });
                log.info('ðŸ§  DeepSeek-V3 (Hugging Face) ready.');
            } catch (error) {
                log.error('Failed to init Hugging Face provider:', error.message);
            }
        }

        // 6. Init Gemini
        if (CONFIG.geminiApiKey) {
            try {
                this.genAI = new GoogleGenerativeAI(CONFIG.geminiApiKey);
                this.geminiModel = this.genAI.getGenerativeModel({
                    model: "gemini-2.0-flash-lite",
                    systemInstruction: this.systemPrompt
                });
                log.info('ðŸ§  Gemini 2.0 Flash Lite (Vision) ready.');
            } catch (error) {
                log.error('Failed to init Gemini provider:', error.message);
            }
        }

        this.isInitialized = !!(this.mistral || this.githubClient || this.groq || this.cohere || this.hfClient || this.geminiModel);
    }

    async init() {
        log.info(`ðŸ§  PsychoBrain (Hexa-Mode) init called.`);
        return true;
    }

    async getHistory(chatId) {
        // 1. MEMORY CACHE (Fastest)
        if (this.memoryHistory.has(chatId)) {
            return this.memoryHistory.get(chatId);
        }

        // 2. MONGO DB PERSISTENCE
        try {
            const History = require('../database/models/History');
            const data = await History.findOne({ chatId });
            if (data) {
                this.memoryHistory.set(chatId, data.messages);
                return data.messages;
            }
        } catch (err) {
            // MongoDB not ready or error
        }

        // 3. LOCAL JSON FALLBACK
        const filePath = path.join(this.historyDir, `${chatId.replace(/[:@]/g, '_')}.json`);
        try {
            if (await fs.exists(filePath)) {
                const localData = await fs.readJson(filePath);
                this.memoryHistory.set(chatId, localData);
                return localData;
            }
        } catch (error) {
            log.error(`Failed to read history for ${chatId}:`, error.message);
        }
        return [];
    }

    pruneCache() {
        if (this.memoryHistory.size > this.maxMemoryChats) {
            const firstKey = this.memoryHistory.keys().next().value;
            this.memoryHistory.delete(firstKey);
            log.debug(`Brain: Pruned oldest chat from memory (${firstKey})`);
        }
    }

    async saveHistory(chatId, history) {
        const limitedHistory = history.slice(-50);

        // 1. UPDATE MEMORY CACHE
        this.memoryHistory.delete(chatId); // Move to the end (LRU)
        this.memoryHistory.set(chatId, limitedHistory);
        this.pruneCache();

        // 2. MONGO DB PERSISTENCE (Async, don't wait)
        const History = require('../database/models/History');
        History.findOneAndUpdate(
            { chatId },
            { messages: limitedHistory, lastUpdated: Date.now() },
            { upsert: true }
        ).catch(e => log.debug(`DB save failed: ${e.message}`));

        // 3. LOCAL JSON FALLBACK (Async, don't wait)
        const filePath = path.join(this.historyDir, `${chatId.replace(/[:@]/g, '_')}.json`);
        fs.writeJson(filePath, limitedHistory.slice(-this.maxHistory)).catch(e => log.debug(`Local save failed: ${e.message}`));
    }

    // New method to record messages without replying
    async logMessage(chatId, senderName, text) {
        const chatHistory = await this.getHistory(chatId);
        chatHistory.push({ role: "user", text: `${senderName}: ${text}` });
        await this.saveHistory(chatId, chatHistory);
    }

    async searchInternet(query) {
        if (!CONFIG.searchApiKey) return null;
        try {
            const response = await axios.get('https://serpapi.com/search', {
                params: {
                    q: query,
                    api_key: CONFIG.searchApiKey,
                    engine: 'google',
                    num: 3
                },
                timeout: 5000
            });
            const results = response.data.organic_results;
            if (results && results.length > 0) {
                return results.map(r => `[${r.title}] ${r.snippet}`).join('\n');
            }
        } catch (error) {
            log.debug(`Search failed: ${error.message}`);
        }
        return null;
    }

    async process(text, chatId = 'global', media = null) {
        if (!this.isInitialized) {
            return "Wesh, mon cerveau est pas encore branchÃ© (API key manquante). Dis Ã  mon boss de checker le .env ! ðŸ”Œ";
        }

        const chatHistory = await this.getHistory(chatId);
        let response = "";

        // --- INTERNET SEARCH TRIGGER ---
        let searchContext = "";
        const searchKeywords = ['news', 'actualitÃ©', 'meteo', 'mÃ©tÃ©o', 'score', 'qui est', 'qu\'est-ce', 'recherche', 'google', 'search', 'tempÃ©rature', 'prix', 'bourse'];
        if (CONFIG.searchApiKey && !media && searchKeywords.some(k => text.toLowerCase().includes(k))) {
            const results = await this.searchInternet(text);
            if (results) {
                searchContext = `\n\n[INFO RÃ‰ELLE DU WEB (Utilise Ã§a pour rÃ©pondre bg)]:\n${results}`;
            }
        }

        const finalText = text + searchContext;

        // MULTIMODAL MODE: GitHub -> Gemini
        if (media) {
            try {
                if (this.githubClient) response = await this.processGitHub(text, chatHistory, media);
                else throw new Error('GITHUB_NOT_READY');
            } catch (err) {
                try {
                    if (this.geminiModel) response = await this.processGemini(text, chatHistory, media);
                    else throw new Error('GEMINI_NOT_READY');
                } catch (errGem) {
                    log.error('Failed to process media with Gemini:', errGem.message);
                    response = "Wesh, j'arrive pas Ã  analyser ton mÃ©dia. Mes yeux me brÃ»lent lÃ  ! ðŸ”¥ðŸ˜µâ€ðŸ’«";
                }
            }
        } else {
            const start = Date.now();
            const providers = [
                { name: 'Mistral', fn: () => this.processMistral(finalText, chatHistory) },
                { name: 'GitHub', fn: () => this.processGitHub(finalText, chatHistory) },
                { name: 'Groq', fn: () => this.processGroq(finalText, chatHistory) },
                { name: 'Cohere', fn: () => this.processCohere(finalText, chatHistory) },
                { name: 'Gemini', fn: () => this.processGemini(finalText, chatHistory) }
            ];

            for (const provider of providers) {
                try {
                    const pStart = Date.now();
                    response = await provider.fn();
                    if (response) {
                        log.info(`âœ… ${provider.name} responded in ${Date.now() - pStart}ms`);
                        break;
                    }
                } catch (err) {
                    log.warn(`âš ï¸ ${provider.name} failed. Trying next...`);
                }
            }

            log.info(`ðŸ§  Total Brain processing time: ${Date.now() - start}ms`);
        }

        if (!response) {
            return "DÃ©solÃ© bg, mes cerveaux sont grillÃ©s. J'arrive plus Ã  rÃ©flÃ©chir. ðŸ˜µâ€ðŸ’«";
        }

        // Record response in history
        chatHistory.push({ role: "model", text: response });
        await this.saveHistory(chatId, chatHistory);

        return response;
    }

    async generateAutoMessage(type) {
        if (!this.isInitialized) return null;

        let prompt = "";
        if (type === 'morning') {
            prompt = "Il est 5h du matin. Envoie un message de bonjour ultra cool et motivant Ã  la communautÃ© XyberClan. Utilise ton flow Psycho Bo (slang camerounais, vibe guerrier tech). Sois court et percutant. ðŸ‡¨ðŸ‡²ðŸ”¥ðŸ¤™";
        } else if (type === 'midnight') {
            prompt = "Il est minuit. C'est l'heure du coding intense. Envoie un message 'Good coding time' aux dÃ©veloppeurs du XyberClan. Encourage-les Ã  brosser le code avec ton flow Psycho Bo. âš”ï¸âš¡ðŸ’»";
        } else {
            return null;
        }

        try {
            // Use Mistral as primary for auto-messages
            if (this.mistral) {
                const response = await this.mistral.agents.complete({
                    agentId: CONFIG.mistralAgentId,
                    messages: [{ role: "user", content: prompt }]
                });
                return response.choices[0].message.content;
            }
            // Fallback to Gemini if Mistral fails
            if (this.geminiModel) {
                const result = await this.geminiModel.generateContent(prompt);
                return result.response.text();
            }
        } catch (error) {
            log.error(`Auto-message generation failed (${type}):`, error.message);
        }
        return null;
    }

    async processMistral(text, chatHistory) {
        if (!this.mistral) throw new Error('MISTRAL_NOT_READY');

        const messages = [
            { role: "system", content: this.systemPrompt },
            ...chatHistory.map(msg => ({
                role: msg.role === 'user' ? 'user' : 'assistant',
                content: msg.text
            })),
            { role: "user", content: text }
        ];

        const result = await this.mistral.agents.complete({
            agentId: CONFIG.mistralAgentId,
            messages: messages
        });

        return result.choices[0].message.content;
    }

    async processGitHub(text, chatHistory, media = null) {
        const content = [{ type: "text", text: text || "Analyse ce mÃ©dia." }];
        if (media) {
            content.push({
                type: "image_url",
                image_url: { url: `data:${media.mimetype};base64,${media.buffer.toString('base64')}` }
            });
        }

        const messages = [
            { role: "system", content: this.systemPrompt },
            ...chatHistory.map(msg => ({
                role: msg.role === 'user' ? 'user' : 'assistant',
                content: msg.text
            })),
            { role: "user", content: content }
        ];

        const completion = await this.githubClient.chat.completions.create({
            model: "gpt-4o-mini",
            messages: messages,
            max_tokens: 512,
            temperature: 0.8
        });

        return completion.choices[0]?.message?.content || "";
    }

    async processGroq(text, chatHistory) {
        const messages = [
            { role: "system", content: this.systemPrompt },
            ...chatHistory.map(msg => ({
                role: msg.role === 'user' ? 'user' : 'assistant',
                content: msg.text
            })),
            { role: "user", content: text }
        ];

        const completion = await this.groq.chat.completions.create({
            model: "llama-3.3-70b-versatile",
            messages: messages,
            max_tokens: 512,
            temperature: 0.8
        });

        return completion.choices[0]?.message?.content || "";
    }

    async processCohere(text, chatHistory) {
        const chat_history = chatHistory.map(msg => ({
            role: msg.role === 'user' ? 'USER' : 'CHATBOT',
            message: msg.text
        }));

        const response = await this.cohere.chat({
            message: text,
            model: 'command-r-plus',
            preamble: this.systemPrompt,
            chatHistory: chat_history
        });

        return response.text;
    }

    async processDeepSeek(text, chatHistory) {
        const messages = [
            { role: "system", content: this.systemPrompt },
            ...chatHistory.map(msg => ({
                role: msg.role === 'user' ? 'user' : 'assistant',
                content: msg.text
            })),
            { role: "user", content: text }
        ];

        const completion = await this.hfClient.chat.completions.create({
            model: "deepseek-ai/DeepSeek-V3",
            messages: messages,
            max_tokens: 500,
            temperature: 0.7
        });

        return completion.choices[0].message.content;
    }

    async processGemini(text, chatHistory, media = null) {
        const parts = [{ text: text || "Analyse ce mÃ©dia." }];
        if (media) {
            parts.push({
                inlineData: {
                    data: media.buffer.toString('base64'),
                    mimeType: media.mimetype
                }
            });
        }

        const contents = chatHistory.map(msg => ({
            role: msg.role === 'user' ? 'user' : 'model',
            parts: [{ text: msg.text }]
        }));

        contents.push({ role: "user", parts: parts });

        const result = await this.geminiModel.generateContent({
            contents: contents,
            generationConfig: { maxOutputTokens: 512, temperature: 0.9 }
        });

        return result.response.text();
    }
}

module.exports = new PsychoBrain();
